{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96ca76a5",
   "metadata": {},
   "source": [
    "# Crawling 기초 실습\n",
    "\n",
    "## Requests 실습"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55a9fa5e",
   "metadata": {},
   "source": [
    "# [BeautifulSoup 라이브러리 실습]\n",
    "# Requests\n",
    "- 웹페이지(html) 읽어오기\n",
    "- 빠르다\n",
    "- 정적 웹페이지\n",
    "r = requests.get('https://api.github.com/user', auth=('user', 'pass'))\n",
    "r.status_code\n",
    "200 -> 이 숫자가 나온다면 성공적으로 된 것\n",
    "\n",
    "# Selenium\n",
    "- 웹페이지 자동화\n",
    "- 느리다\n",
    "- 동적 웹페이지 (스크롤, 로그인...)\n",
    "\n",
    "# BeautifulSoup\n",
    "- 원하는 데이터 가져오기 (스크래핑)\n",
    "\n",
    "# User agent\n",
    "- 내가 어떤 브라우저를 사용해서 접속했는지 알려주기 위해 사용\n",
    "- 서버에서 사람아니고 로봇이라고 판단하여 Requests에서 200이 안 나올 경우 사람이라고 가짜로 알려주기 위함\n",
    "- 'my user agent'로 검색해서 나온 정보를 headers에 넣어줌\n",
    "\n",
    "# Requests 코드\n",
    "headers = {'User-Agent' : '유저정보'}\n",
    "url = '접속할 사이트'\n",
    "requests.get(url, headers = headers)\n",
    "\n",
    "# Beautifulsoup\n",
    "- 이것을 통해 원하는 정보에 접속\n",
    "- pip install beautiifulsoup4로 설치\n",
    "\n",
    "# find\n",
    "- 처음 나오는 원하는 태그의 값만 가져옴\n",
    "\n",
    "# find_all\n",
    "- 원하는 태그의 모든 값을 가져옴\n",
    "- 결과물은 리스트 타입\n",
    "\n",
    "# .text\n",
    "- 텍스트만 가져오기\n",
    "- find_all()로 가져온 정보는 반복문을 통해 하나씩 가져올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27de9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests 불러오기\n",
    "import requests    # 설치가 되어있지 않다면 pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19758651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# headers에 'User-Agent' 값 넣기\n",
    "headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'}\n",
    "\n",
    "# url에 주소 넣기\n",
    "url = 'https://www.transfermarkt.com/'\n",
    "\n",
    "# requests.get()으로 요청하기\n",
    "r = requests.get('https://www.transfermarkt.com/', headers = headers)\n",
    "\n",
    "# status_code 응답 확인하기\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0471e3",
   "metadata": {},
   "source": [
    "## BeautifulSoup Quick Start 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ca323ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6657bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cff1de33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"title\"><b>The Dormouse's story</b></p>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p 태그 정보 가져오기 (처음 나오는 것 한 개)\n",
    "soup.p\n",
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f06fdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://example.com/elsie'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a 태그에 있는 'href' 속성값 가져오기 (처음 나오는 것 한 개)\n",
    "soup.find('a')['href']\n",
    "soup.a['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "201d903c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elsie'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a 태그에 있는 텍스트 가져오기 (처음 나오는 것 한 개)\n",
    "soup.find('a').text\n",
    "soup.find('a').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b632a3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a 태그에 있는 요소들 모두 가져오기\n",
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a0e93e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 번째 a 태그에 있는 정보 가져오기\n",
    "soup.find_all('a')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a02d4793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/elsie\n",
      "http://example.com/lacie\n",
      "http://example.com/tillie\n"
     ]
    }
   ],
   "source": [
    "# a 태그에 있는 'href' 속성값 모두 가져오기\n",
    "a_list = soup.find_all('a')\n",
    "\n",
    "for i in a_list:\n",
    "    print(i['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6ab12bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elsie\n",
      "Lacie\n",
      "Tillie\n"
     ]
    }
   ],
   "source": [
    "# a 태그에 있는 텍스트 모두 가져오기\n",
    "a_list = soup.find_all('a')\n",
    "\n",
    "for i in a_list:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62f6eb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 태그와 속성값을 같이 넣어 찾아오기\n",
    "# a 태그이면서 class가 sister인 값 모두 찾아오기\n",
    "soup.find_all('a', class_= 'sister')    # class만 적으면 키워드가 되어서 뒤에 _ 하나를 적음\n",
    "soup.find_all('a', {\"class\" : \"sister\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbfbe22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a 태그이면서 id가 link3인 요소들 모두 찾기\n",
    "soup.find_all('a', id = 'link3')\n",
    "soup.find_all('a', {\"id\" : \"link3\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
